---
title: "크롤링에 selenium 활용하기"
tag : 
   - Python 
   - selenium
---

## selenium?
 * selenium은 주로 웹 App을 테스트하는 웹 프레임워크입니다.
 * selenium은  Firefox, IE, Chrome 등과 같은 Selenium WebDriver에 액세스 할 수있는 편리한 API를 제공합니다. 
 * 자바스크립트에 의해 동적으로 생성되는 사이트의 데이터를 크롤링할 때 매우 유용하게 사용되는 스크래핑 도구
 * 현재 지원되는 Python 버전은 2.7, 3.5 이상입니다.
 
## selenium 사용법
 * 설치
 
```python
pip install selenium

from selenium import webdriver

path = 'webdriver path'
dirver = webdriver.Chrome(path)

단일 element 접근 메소드
dirver.find_element_by_name('HTML_name')
dirver.find_element_by_id('HTML_id')
dirver.find_element_by_xpath('/html/body/some/xpath')
dirver.find_element_by_css_selector('#css > div.selector')
dirver.find_element_by_class_name('some_class_name')
dirver.find_element_by_tag_name('h1')
```

 * 간단한 예제

```python
# google search

from selenium import webdriver

path = './chromedriver.exe'
driver = webdriver.Chrome(path)

driver.get('http://google.com')
search = driver.find_element_by_name('q')
search.send_keys('python djagno')
search.submit()

# Naver Search

from selenium import webdriver

path = './chromedriver.exe'
driver = webdriver.Chrome(path)

driver.get('http://naver.com')
search = driver.find_element_by_name('query')
search.send_keys('python django')
search.submit()

# Naver Sports Title Crawling

import urllib.request
import bs4

url = 'https://sports.news.naver.com/index.nhn'
html = urllib.request.urlopen(url)

bs_obj = bs4.BeautifulSoup(html, "html.parser")
head_line = bs_obj.find("ul", {"class":"main_headline_small"})
head_line_tile = head_line.find_all("span", {"class":"text"})

for title in head_line_tile:
    print(title)
    

```

* 페이스북 로그인하기

```python

#facebook login
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from getpass import getpass

def facebook_login(user_id, user_pw):
    path = './chromedriver.exe'
    driver = webdriver.Chrome(path)
    driver.get("https://www.facebook.com/")
    
    elem = driver.find_element_by_id("email")
    elem.send_keys(user_id)
    elem = driver.find_element_by_id("pass")
    elem.send_keys(user_pw)
    
    # Enter를 누르게함
    elem.send_keys(Keys.RETURN)

if __name__ == '__main__':
    user_id = input('ID Input :')
    user_pw = getpass('passwd : ')
    
    facebook_login(user_id, user_pw)
```

* 네이버 로그인 후 메일리스트 받아오기

```python

# Naver Login
import time

from getpass import getpass

from selenium import webdriver
from selenium.webdriver.common.keys import Keys

from bs4 import BeautifulSoup

def naver_login(naver_id, passwd):
    path = './chromedriver.exe'
    driver = webdriver.Chrome(path)

    driver.get('https://nid.naver.com/nidlogin.login')
    
    # Naver CAPCHA로 인해 로그인불가(사람인지 컴퓨터인지 구별하는 프로그램)
    #elem = driver.find_element_by_name('id')
    #elem.send_keys(naver_id)
    #elem = driver.find_element_by_name('pw')
    #elem.send_keys(passwd)
    
    # Enter를 누르게함
    #elem.send_keys(Keys.RETURN)
    
    # 우회하여 script단에서 value값을 변경한다.
    # execute_script 자바스크립트 코드를 실행할 수 있다.
    driver.execute_script("document.getElementsByName('id')[0].value=\'" + naver_id + "\'")
    driver.execute_script("document.getElementsByName('pw')[0].value=\'" + passwd + "\'")

    driver.find_element_by_xpath('//*[@id="frmNIDLogin"]/fieldset/input').click()
    
    
    #sleep을 주지않으면 login URL로 나온다.
    time.sleep(2)
    if 'nidlogin.login' in driver.current_url:
        print('로그인 실패')
        return None
    

if __name__ == '__main__':
    naver_id = input('Naver ID : ')
    passwd = getpass('password : ')
    
    naver_login(naver_id, passwd)
```
